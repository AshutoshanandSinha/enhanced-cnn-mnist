{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e9e8c9-9b9b-41c8-b334-d3e56b7ba715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a6760c-93e2-45db-9a0a-86347dd9576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rf_calc in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from rf_calc) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from rf_calc) (2.2.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from rf_calc) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from pandas>=1.1.5->rf_calc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from pandas>=1.1.5->rf_calc) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from pandas>=1.1.5->rf_calc) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashutoshanandsinha/Documents/ERA3/assignment8/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->rf_calc) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rf_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c89e0-0ec6-484b-a510-3a9ac798ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Layer (type)               Output Shape         Param #\n",
      "======================================================================\n",
      "layer1                    torch.Size([1, 8, 26, 26]) 88\n",
      "layer2                    torch.Size([1, 8, 24, 24]) 592\n",
      "layer3                    torch.Size([1, 12, 22, 22]) 888\n",
      "layer4                    torch.Size([1, 12, 20, 20]) 1320\n",
      "pool                      torch.Size([1, 12, 10, 10]) 0\n",
      "layer5                    torch.Size([1, 8, 8, 8]) 880\n",
      "layer6                    torch.Size([1, 16, 6, 6]) 1184\n",
      "layer7                    torch.Size([1, 12, 4, 4]) 1752\n",
      "layer8                    torch.Size([1, 10, 2, 2]) 1100\n",
      "avgpool                   torch.Size([1, 10, 1, 1]) 0\n",
      "layer9                    torch.Size([1, 10, 1, 1]) 100\n",
      "======================================================================\n",
      "Total params: 7904\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating dataset statistics: 100%|██████████████████████████████████████████████████████████| 60/60 [00:11<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics - Mean: 0.1307, Std: 0.3015\n",
      "Number of parameters: 7904\n",
      "Model validation successful: Parameters within limit\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.1463 Batch_id=468 Accuracy=89.43: 100%|███████████████████████████████████████████████| 469/469 [01:52<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0677, Accuracy: 9823/10000 (98.23%)\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Training - Loss: 0.4335, Accuracy: 89.43%\n",
      "Testing  - Accuracy: 98.23%\n",
      "Best Test Accuracy: 98.23%\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0774 Batch_id=468 Accuracy=98.01: 100%|███████████████████████████████████████████████| 469/469 [01:29<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0423, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Training - Loss: 0.0730, Accuracy: 98.01%\n",
      "Testing  - Accuracy: 98.76%\n",
      "Best Test Accuracy: 98.76%\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0707 Batch_id=468 Accuracy=98.34: 100%|███████████████████████████████████████████████| 469/469 [01:29<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Training - Loss: 0.0556, Accuracy: 98.34%\n",
      "Testing  - Accuracy: 98.86%\n",
      "Best Test Accuracy: 98.86%\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0513 Batch_id=468 Accuracy=98.60: 100%|███████████████████████████████████████████████| 469/469 [02:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0351, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training - Loss: 0.0470, Accuracy: 98.60%\n",
      "Testing  - Accuracy: 98.88%\n",
      "Best Test Accuracy: 98.88%\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0785 Batch_id=468 Accuracy=98.73: 100%|███████████████████████████████████████████████| 469/469 [01:43<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training - Loss: 0.0428, Accuracy: 98.73%\n",
      "Testing  - Accuracy: 99.11%\n",
      "Best Test Accuracy: 99.11%\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0158 Batch_id=468 Accuracy=98.84: 100%|███████████████████████████████████████████████| 469/469 [01:24<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training - Loss: 0.0389, Accuracy: 98.84%\n",
      "Testing  - Accuracy: 98.99%\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0236 Batch_id=468 Accuracy=99.21: 100%|███████████████████████████████████████████████| 469/469 [01:02<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 9941/10000 (99.41%)\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training - Loss: 0.0275, Accuracy: 99.21%\n",
      "Testing  - Accuracy: 99.41%\n",
      "Best Test Accuracy: 99.41%\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0195 Batch_id=468 Accuracy=99.28: 100%|███████████████████████████████████████████████| 469/469 [00:57<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training - Loss: 0.0255, Accuracy: 99.28%\n",
      "Testing  - Accuracy: 99.36%\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0487 Batch_id=468 Accuracy=99.29: 100%|███████████████████████████████████████████████| 469/469 [00:48<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training - Loss: 0.0248, Accuracy: 99.29%\n",
      "Testing  - Accuracy: 99.39%\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0233 Batch_id=468 Accuracy=99.32: 100%|███████████████████████████████████████████████| 469/469 [00:42<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 9940/10000 (99.40%)\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training - Loss: 0.0239, Accuracy: 99.32%\n",
      "Testing  - Accuracy: 99.40%\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0275 Batch_id=468 Accuracy=99.33: 100%|███████████████████████████████████████████████| 469/469 [00:41<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 9942/10000 (99.42%)\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training - Loss: 0.0231, Accuracy: 99.33%\n",
      "Testing  - Accuracy: 99.42%\n",
      "Best Test Accuracy: 99.42%\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0079 Batch_id=468 Accuracy=99.33: 100%|███████████████████████████████████████████████| 469/469 [00:49<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training - Loss: 0.0230, Accuracy: 99.33%\n",
      "Testing  - Accuracy: 99.36%\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0096 Batch_id=468 Accuracy=99.37: 100%|███████████████████████████████████████████████| 469/469 [00:43<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training - Loss: 0.0225, Accuracy: 99.37%\n",
      "Testing  - Accuracy: 99.38%\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0324 Batch_id=468 Accuracy=99.39: 100%|███████████████████████████████████████████████| 469/469 [01:06<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training - Loss: 0.0220, Accuracy: 99.39%\n",
      "Testing  - Accuracy: 99.39%\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0353 Batch_id=468 Accuracy=99.37: 100%|███████████████████████████████████████████████| 469/469 [00:57<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training - Loss: 0.0219, Accuracy: 99.37%\n",
      "Testing  - Accuracy: 99.37%\n",
      "\n",
      "Training completed!\n",
      "Best Test Accuracy: 99.42%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F  # Add this line\n",
    "\n",
    "from tqdm import tqdm\n",
    "from model import SimpleMNISTNet\n",
    "\n",
    "# Global lists for tracking metrics\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "\n",
    "        loss = F.nll_loss(y_pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        processed += len(data)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.set_description(\n",
    "            desc=f'Loss={loss.item():.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:.2f}'\n",
    "        )\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100. * correct / processed\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_acc.append(epoch_accuracy)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)  # Calculate accuracy\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))  # Use the calculated accuracy\n",
    "\n",
    "    test_acc.append(accuracy)  # Append accuracy to the list\n",
    "    return accuracy  # Return the accuracy value\n",
    "\n",
    "def validate_model(model, device, train_loader):\n",
    "    # Check the number of parameters\n",
    "    num_params = model.count_parameters()\n",
    "    print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "    # Validate only parameter count\n",
    "    if num_params < 50000:\n",
    "        print(\"Model validation successful: Parameters within limit\")\n",
    "        return True\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Model validation failed: Parameters={num_params} (limit: 50000)\"\n",
    "        )\n",
    "\n",
    "def train_and_test():\n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Model initialization\n",
    "    network = SimpleMNISTNet().to(device)\n",
    "    network.print_model_summary()\n",
    "\n",
    "    # Calculate dataset statistics\n",
    "    initial_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    temp_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=initial_transform\n",
    "    )\n",
    "    mean, std = calculate_dataset_statistics(temp_dataset)\n",
    "    print(f\"Dataset statistics - Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "\n",
    "    # Transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean,), (std,))\n",
    "    ])\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomRotation((-7, 7)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean,), (std,)),\n",
    "    ])\n",
    "\n",
    "    # Datasets and Loaders\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Validate the model\n",
    "    validate_model(network, device, train_loader)\n",
    "\n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "\n",
    "    # Training Loop\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(15):\n",
    "        print(f\"\\nEpoch {epoch+1}/15\")\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_accuracy = train(network, device, train_loader, optimizer, epoch)\n",
    "\n",
    "        # Testing phase\n",
    "        test_accuracy = test(network, device, test_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}\")\n",
    "        print(f\"Training - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Testing  - Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            print(f\"Best Test Accuracy: {best_accuracy:.2f}%\")\n",
    "            torch.save(network.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Best Test Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "def calculate_dataset_statistics(dataset):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1000,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in tqdm(loader, desc=\"Calculating dataset statistics\"):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "\n",
    "    return mean.item(), std.item()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208aaeb9-3597-441a-a5d1-0efaaab148ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
